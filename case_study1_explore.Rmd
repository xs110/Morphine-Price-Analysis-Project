---
title: "Case Study 1 - Explore"
author: "Weiting Miao"
date: "2023-10-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align = 'center')
```



```{r, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(car)
library(lme4)
library(lmerTest)
library(lattice)
library(merTools)
library(gridExtra)
library(mice)
library(kableExtra)
```

```{r}
#load data
load("streetrx.RData")
df <- streetrx %>%
  filter(api_temp == "morphine", !is.na(ppm))
```

Data Cleaning
(1). Drop observations if the outcome variable is missing
(2). Source - factor: Heard it, Personal, Internet, Unknown
(3). Dosage strength - group them or not?

### Questions of Interest
To investigate factors related to the price per mg of your drug, accounting for potential clustering by location and exploring heterogeneity in pricing by location.

Variables:

- Outcome variable: ppm
- Purchasing time: year, month, day, quarter
- Location: country, state, city
- Source: source of information               - Unknown
- Formulation of the drug: factor             - no variation
- Dosage strength                             - whether treat it as factor or numeric variable, or group them
- Bulk Purchase: dummy
- Primary reason: factor                      - many missing values
## Missing data imputation

### preprocess data
```{r}
# If df == "", them map to NA
# Replace empty strings with NA
df[df == ""] <- NA
md.pattern(df,rotate.names = TRUE)
```
At the bottom: total number of missing values by variables.
On the right: number of variables missing in each pattern.
On the left: number of cases for each pattern.

Missing data:
State has 1 missing values, and it has wrong category "USA", so we also map to unknown
City has 3126 missing values and duplicate entries as well as abbreviations, so we need to preprocess city(or just drop it). 
source has 3695 missing values and messy website.
Primary_Reason has 4754 missing values

Next step: preprocess these columns then use mice to impute missing values.

```{r}
result <- df %>%
  group_by(Primary_Reason) %>%
  summarise(Count = n()) %>%
  arrange(-Count)  # Sorting in descending order

# Print the sorted table
kable(result)
```
```{r}
#city
# # briefly preprocess data for data with over 4 counts.
# # Convert city names to title case
# df$city <- str_to_title(df$city)
# 
# # Create a mapping for abbreviations and other variations
# corrections <- data.frame(
#   original = c("Phx", "Dallas - Fort Worth", "philadelphia Pa", "Sacramento california", "Los Angeles California", "Nashville tn", "San Francisco California City", "saint Louis", "Sf"),
#   corrected = c("Phoenix", "Dallas", "Philadelphia", "Sacramento", "Los Angeles", "Nashville", "San Francisco", "Saint Louis", "San Francisco")
# )
# 
# # Use the mapping to replace city names
# df <- df %>%
#   left_join(corrections, by = c("city" = "original")) %>%
#   mutate(city = ifelse(is.na(corrected), city, corrected))

```


```{r}
# state
df <- df%>%
  mutate(state = case_when(
    state == "USA" ~ "Unknown",
    is.na(state) ~ "Unknown",
    TRUE ~ state
  ))
```

```{r}
# source
df$source <- as.character(df$source)
df$source <- ifelse(grepl("^http", df$source), "Internet", df$source)

freq_df_source <- as.data.frame(table(df$source))
colnames(freq_df_source) <- c("Value", "Frequency")
freq_df_source[freq_df_source$Frequency > 50, ]

df <- df %>%
  mutate(source = case_when(
    # is.null(source)  ~ "Unknown", ## doesn't work
    # is.na(source)  ~ "Unknown",
    # source == "" ~ "Unknown",
    source == "Heard it" ~ "Heard it",
    source == "Personal" ~ "Personal",
    source == "Internet Pharmacy" ~ "Internet Pharmacy",
    !is.na(source) & source != "Personal" & source != "Heard it" & source != "Internet Pharmacy" ~ "Internet",
    source == "L" ~ NA,
    TRUE ~ source
  ))


table(df$form_temp) ## almost all are pill/tablet -> not include it in the model
table(df$mgstr) ## whether treat it as factor or numeric variable, or group them
table(df$bulk_purchase)
table(df$Primary_Reason) ## many missing values -> not include it in the model

# remove states with 1 observation
df <- df %>%
  group_by(state) %>%
  mutate(count = n()) %>%
  filter(count > 1) 
table(df$state)


# code factors and numeric variables 
df <- df %>%
  mutate(ppm = as.numeric(ppm), 
         price_date = mdy(price_date),
         year = year(price_date),
         city = as.factor(city), 
         state = as.factor(state),
         country = as.factor(country),
         USA_region = as.factor(USA_region),
         source = as.factor(source),
         mgstr = as.numeric(mgstr),
         bulk_purchase = as.factor(bulk_purchase)
         )

df$quarter = as.numeric(substr(df$yq_pdate, nchar(df$yq_pdate), nchar(df$yq_pdate)))

df <- df %>% filter(year>=2010)
```

```{r}
table(df$source)
table(df$state)
table(df$USA_region)
```

```{r}
# log ppm
df$log_ppm <- log(df$ppm)

hist_ppm <- ggplot(df, aes(x=ppm)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white", bins = 50)

hist_log_ppm <- ggplot(df, aes(x=log_ppm)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white", bins = 50)
grid.arrange(hist_ppm, hist_log_ppm, ncol=2)

df <- df %>% filter(ppm > 0)
```

### Imputation

We assume that the data is MAR, the next step is to build models to predict missing data from observed data.
One problem: city has over 50 categories and is messed up with duplicate and abbreviation, so here we will drop city and focus on factor variables: state, USA_region

```{r}
library(VIM)
aggr(df,col=c("lightblue3","darkred"),numbers=TRUE,sortVars=TRUE,
labels=names(df),cex.axis=.7,gap=3,
ylab=c("Proportion missing","Missingness pattern"))
```
The typical sequence of steps to perform a multiple imputation analysis is:

1) Impute the missing data by the mice() function, resulting in a multiple imputed data set (class mids);

2) Fit the model of interest (scientific model) on each imputed data set by the with() function, resulting an object of class mira;

3) Pool the estimates from each model into a single set of estimates and standard errors, resulting in an object of class mipo;

4) Optionally, compare pooled estimates from different scientific models by the D1() or D3() functions.
```{r}
#drop city
df <- subset(df, select = -city)
# multiple impute the missing values
imp <- mice(df, maxit = 2, m = 2, seed = 1)
```

```{r}
fit <- with(imp,  lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 | state)))
tab <- summary(pool(fit), "all", conf.int = TRUE)
as.numeric(tab[tab$term == "year", c("estimate", "2.5 %", "97.5 %")])
```


```{r}
fit3 <- with(imp, anova(lmer(log_ppm ~ year +  mgstr + bulk_purchase + source+ (1 | state))))
```












```{r}
### random intercept

ggplot(df, aes(x=log_ppm, y=reorder(state, state, length))) +
  geom_boxplot(outlier.size = 0.1) +
  labs(title="Log(ppm) by State", x = "Log(ppm)", y = "State")

```

```{r}
eda_year = ggplot(data = df %>% filter(year>2009), aes(x = year, y = log_ppm)) +
  geom_point(size = 0.5, alpha = 0.5) +   
  geom_line(size = 0.5, alpha = 0.2) +
  geom_smooth( method = "loess", se = FALSE, size = 1.5) + 
  labs(x = "Year",
       y = "Log(ppm)")

eda_quarter = ggplot(data = df %>% filter(year>2009), aes(x = quarter, y = log_ppm)) +
  geom_point(size = 0.5, alpha = 0.5) +   
  geom_line(size = 0.5, alpha = 0.2) +
  geom_smooth( method = "loess", se = FALSE, size = 1.5) + 
  labs(x = "Quarter",
       y = "Log(ppm)")

grid.arrange(eda_year, eda_quarter, ncol=2)
```

Year effect is not linear. Should consider year as a factor variable.



```{r}
df$year = as.factor(df$year)
df$quarter = as.factor(df$quarter)

mgstr_ppm <- ggplot(df, aes(x = factor(mgstr), y = log(ppm))) + 
    geom_boxplot(aes(fill = factor(mgstr)), outlier.size = 0.1) + 
  labs(x = "mgstr") + 
  theme(legend.position = "none") +
  coord_flip()

bp_ppm <- ggplot(df, aes(x = bulk_purchase, y = log(ppm))) + 
    geom_boxplot(aes(fill = bulk_purchase), outlier.size = 0.1) + 
  labs(x = "Bulk Purchase") + 
  theme(legend.position = "none") + 
  coord_flip()

source_ppm <- ggplot(df, aes(x = source, y = log(ppm))) + 
    geom_boxplot(aes(fill = source), outlier.size = 0.1) + 
  labs(x = "Source") + 
  theme(legend.position = "none") +
  coord_flip()


grid.arrange(mgstr_ppm, bp_ppm, source_ppm, ncol=2)
```

Might have interaction effect..

```{r}
ggplot(df, aes(x = mgstr, y = log(ppm))) + 
  geom_point() +
  geom_smooth( method = "loess") +
  facet_wrap(~bulk_purchase)


ggplot(df, aes(x = mgstr, y = log(ppm))) + 
  geom_point() +
  geom_smooth( method = "loess") +
  facet_wrap(~quarter)

ggplot(df, aes(x = bulk_purchase, y = log(ppm))) + 
  geom_boxplot() +
  facet_wrap(~quarter)
```






### Model Building & Model Selection

Predictors: year, quarter, mgstr, bulk_purchase, source, 
Random intercept: state
Random slope: ? state by 

```{r}
## whether to include quarter

m1 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 | state), data=df)
m2 <- lmer(formula = log_ppm ~ year + quarter + mgstr + bulk_purchase + source + (1 | state), data=df)
anova(m1,m2)
```
```{r}
## whether to include interaction terms

m1 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 | state), data=df)
m3 <- lmer(formula = log_ppm ~ year +  mgstr*bulk_purchase + source + (1 | state), data=df)
anova(m1,m3)
```
```{r}
## whether to include random slope

m1 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 | state), data=df)
m4 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 +  mgstr | state), data=df)
anova(m1,m4)
```

```{r}
## whether to include more random slope - No

m4 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 +  mgstr | state), data=df)
m5 <- lmer(formula = log_ppm ~ year +  mgstr + bulk_purchase + source + (1 +  mgstr + bulk_purchase| state), data=df)

anova(m4,m5)
```
```{r}
## any systematic way to check the model performance of different combination?
```

### Model Diagnostics

```{r}
plot(m4)

residual <- resid(m4)

ggplot() + geom_density(aes(x = residual))

```




